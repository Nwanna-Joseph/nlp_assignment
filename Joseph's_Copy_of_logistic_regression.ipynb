{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nwanna-Joseph/nlp_week_1_solution/blob/week1/Joseph's_Copy_of_logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU5EBreqTX9X"
      },
      "source": [
        "In this second part of the lab, we will implement a language identifier trained on the same data, but using Logistic Regression instead of Naive Bayes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "GrqvEG7dTX9Z"
      },
      "outputs": [],
      "source": [
        "import io, sys, math\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lekgm7GdTX9a"
      },
      "source": [
        "This function is used to build the dictionary, or vocabulary, which is a mapping from strings (or words) to integers (or indices). This will allow to build vector representations of documents. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm train1.txt train2.txt valid1.txt valid2.txt __MACOSX/._valid2.txt __MACOSX/._valid1.txt __MACOSX/._train2.txt __MACOSX/._train1.txt\n",
        "!wget -O save.zip https://github.com/Nwanna-Joseph/nlp_week_1_solution/blob/week1/data.zip?raw=true\n",
        "!unzip save.zip\n",
        "!rm save.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAO56IeGwldm",
        "outputId": "5ad8383f-54c0-41cf-81c9-e5b6b920f3ac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-16 14:00:21--  https://github.com/Nwanna-Joseph/nlp_week_1_solution/blob/week1/data.zip?raw=true\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/Nwanna-Joseph/nlp_week_1_solution/raw/week1/data.zip [following]\n",
            "--2022-05-16 14:00:21--  https://github.com/Nwanna-Joseph/nlp_week_1_solution/raw/week1/data.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Nwanna-Joseph/nlp_week_1_solution/week1/data.zip [following]\n",
            "--2022-05-16 14:00:22--  https://raw.githubusercontent.com/Nwanna-Joseph/nlp_week_1_solution/week1/data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2541811 (2.4M) [application/zip]\n",
            "Saving to: ‘save.zip’\n",
            "\n",
            "save.zip            100%[===================>]   2.42M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-05-16 14:00:22 (37.8 MB/s) - ‘save.zip’ saved [2541811/2541811]\n",
            "\n",
            "Archive:  save.zip\n",
            "  inflating: valid2.txt              \n",
            "  inflating: __MACOSX/._valid2.txt   \n",
            "  inflating: valid1.txt              \n",
            "  inflating: __MACOSX/._valid1.txt   \n",
            "  inflating: train2.txt              \n",
            "  inflating: __MACOSX/._train2.txt   \n",
            "  inflating: train1.txt              \n",
            "  inflating: __MACOSX/._train1.txt   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FWLkp40RTX9a"
      },
      "outputs": [],
      "source": [
        "def build_dict(filename, threshold=1):\n",
        "    fin = io.open(filename, 'r', encoding='utf-8')\n",
        "    word_dict, label_dict = {}, {}\n",
        "    counts = defaultdict(lambda: 0)\n",
        "    for line in fin:\n",
        "        tokens = line.split()\n",
        "        label = tokens[0] #ie __label__it\n",
        "        \n",
        "\n",
        "        if not label in label_dict:\n",
        "            label_dict[label] = len(label_dict) #add label (ie __label__it) to dictionary of labels and assign a value of it's index to it\n",
        "\n",
        "        for w in tokens[1:]: # for the remianing words after the first\n",
        "            counts[w] += 1 # word[i]++ ie counts['car'] = counts['car']++. Increment count of car by 1\n",
        "            \n",
        "    for k, v in counts.items(): # k = word, v = frequency\n",
        "        if v > threshold: #only words with frequency above a certain threshold are processed\n",
        "            word_dict[k] = len(word_dict) # add the word to word-dict indexed by word and value = it's position in the list\n",
        "    return word_dict, label_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSQUeb_ATX9b"
      },
      "source": [
        "This function is used to load the training dataset, and build vector representations of the training examples. In particular, a document or sentence is represented as a bag of words. Each example correspond to a sparse vector ` x` of dimension `V`, where `V` is the size of the vocabulary. The element `j` of the vector `x` is the number of times the word `j` appears in the document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Qv3cLjCaTX9b"
      },
      "outputs": [],
      "source": [
        "def load_data(filename, word_dict, label_dict):\n",
        "    fin = io.open(filename, 'r', encoding='utf-8')\n",
        "    data = []\n",
        "    dim = len(word_dict)\n",
        "    for line in fin:\n",
        "        tokens = line.split()\n",
        "        label = tokens[0] #ie __label__it\n",
        "\n",
        "        yi = label_dict[label]\n",
        "        xi = np.zeros(dim)\n",
        "        for word in tokens[1:]:\n",
        "            if word in word_dict:\n",
        "                wid = word_dict[word]\n",
        "                xi[wid] += 1.0\n",
        "        data.append((yi, xi))\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"train1.txt\"\n",
        "word_dict = build_dict(file_name)\n",
        "data_loader = load_data(file_name,word_dict[0],word_dict[1])"
      ],
      "metadata": {
        "id": "uR5SDhNDzIKK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dimension of data => [{len(data_loader)} samples x {len(data_loader[0][1])} features (aka unique words)] \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A0Vla0vznZM",
        "outputId": "b51a2a95-0834-4682-cb2a-e57a86382b91"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension of data => [10000 samples x 5826 features (aka unique words)] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader"
      ],
      "metadata": {
        "id": "AkLbSacLzcSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwjR009CTX9b"
      },
      "source": [
        "First, let's implement the softmax function. Don't forget numerical stability!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "rKRiJz1dTX9c"
      },
      "outputs": [],
      "source": [
        "#https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.softmax.html\n",
        "\n",
        "def softmax(x):\n",
        "  _in_exp = np.exp(x)\n",
        "  max_indx = np.argmax(_in_exp)\n",
        "  num = _in_exp - _in_exp[max_indx]\n",
        "  denom = np.sum(num)\n",
        "  return num / denom"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "softmax(np.array([-1, 0, 1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPIso7iMl17D",
        "outputId": "36cd62d4-8a97-4597-e878-01a45f0e5179"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.5776812,  0.4223188, -0.       ])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQczbOQ7TX9c"
      },
      "source": [
        "Now, let's implement the main training loop, by using stochastic gradient descent. The function will iterate over the examples of the training set. For each example, we will first compute the loss, before computing the gradient and performing the update."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "klf8ARx1TX9c"
      },
      "outputs": [],
      "source": [
        "from matplotlib.ticker import IndexLocator\n",
        "def sgd(w, data, niter):\n",
        "\n",
        "  def predict(weight,X):\n",
        "    return 1/(1 + np.exp( (X@weight) * -1 ))\n",
        "  \n",
        "  def calculate_loss(Y_actual,Y_prediction):\n",
        "    # print(Y_actual.shape,Y_prediction.shape)\n",
        "    return (np.sum( (Y_actual * np.log(Y_prediction)) + ( (1-Y_actual) * np.log(1-Y_prediction) ) ))/(len(Y_actual) * -1)\n",
        "    \n",
        "  def calculate_gradient(X, Y_actual, Y_prediction):\n",
        "    return X.T @ (Y_prediction - Y_actual)\n",
        "\n",
        "  lr = 0.00000001\n",
        "  losses = []\n",
        "\n",
        "  for iter in range(niter):\n",
        "      for idx,each_batch in enumerate([data]):\n",
        "        Y = np.array([_y[0] for _y in each_batch])\n",
        "        Y = Y.reshape(Y.shape[0],-1)\n",
        "        X = np.array([_x[1] for _x in each_batch])\n",
        "        X = X.reshape(X.shape[0],-1) # not necessary. Dimensions remain the same\n",
        "        Y_pred = predict(w,X)\n",
        "        loss = calculate_loss(Y, Y_pred)\n",
        "        losses.append(loss)\n",
        "        if(loss < 0.00):\n",
        "          return w, losses\n",
        "        print(f\"Loss [epoch = {iter}], [batch = {idx}] = {loss}\")\n",
        "        step_size = calculate_gradient(X,Y,Y_pred)\n",
        "        w -= lr * step_size\n",
        "\n",
        "\n",
        "  return w, losses\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyV4tPLwTX9d"
      },
      "source": [
        "The next function will predict the most probable label corresponding to example `x`, given the trained classifier `w`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQx3dE2TTX9d"
      },
      "source": [
        "Finally, this function will compute the accuracy of a trained classifier `w` on a validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "sevRE3T9TX9d"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(w, data):\n",
        "  def predict(weight,X):\n",
        "    return 1/(1 + np.exp( (X@weight) * -1 ))\n",
        "\n",
        "  c=0\n",
        "  x_test = np.array([_x[1] for _x in data])\n",
        "  x_test = x_test.reshape(x_test.shape[0],-1)\n",
        "  y_test = np.array([_y[0] for _y in data])\n",
        "  y_test = y_test.reshape(y_test.shape[0],-1)\n",
        "\n",
        "  y_pred=predict(w,x_test)\n",
        "  print(y_pred.shape,y_test.shape)\n",
        "  for i in range(len(y_test)):\n",
        "    if np.argmax(softmax(y_pred[i])) == y_test[i]:\n",
        "      c+=1\n",
        "  return c/len(y_test)\n",
        "    ## FILL CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aG0ohIxyTX9d"
      },
      "outputs": [],
      "source": [
        "print(\"\")\n",
        "print(\"** Logistic Regression **\")\n",
        "print(\"\")\n",
        "\n",
        "word_dict, label_dict = build_dict(\"train1.txt\")\n",
        "train_data = load_data(\"train1.txt\", word_dict, label_dict)\n",
        "valid_data = load_data(\"valid1.txt\", word_dict, label_dict)\n",
        "\n",
        "nlabels = len(label_dict)\n",
        "dim = len(word_dict)\n",
        "\n",
        "print(f\"Labels = {nlabels}, Features = {dim}\")\n",
        "w = np.zeros([dim,nlabels])\n",
        "w, losses = sgd(w, train_data, 5000)\n",
        "print(\"\")\n",
        "print(\"Validation accuracy: %.3f\" % compute_accuracy(w, valid_data))\n",
        "print(\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"Loss\")\n",
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2rAM9K6Dwwy8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "1cc93f9c-403e-4f49-e829-6156d5fec73b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2+"
    },
    "colab": {
      "name": "Joseph's Copy of logistic_regression.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}